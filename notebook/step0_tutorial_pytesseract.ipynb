{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutoriel pytesserac : https://www.datacamp.com/fr/tutorial/optical-character-recognition-ocr-in-python-with-pytesseract?dc_referrer=https%3A%2F%2Fwww.google.com%2F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre tâche consiste à lire le texte de l'image suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714048579/image_a30b607189.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous définissons le chemin de l'image et l'envoyons à la fonction cv2.imread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "easy_text_path = \"../data/tutorial/images/easy_text.jpg\"\n",
    "easy_img = cv2.imread(easy_text_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous transmettons l'image chargée à la fonction image_to_string de pytesseract pour extraire le texte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is\n",
      "easy to extract.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to text\n",
    "text = pytesseract.image_to_string(easy_img)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est aussi simple que cela ! Transformons ce que nous venons de faire en une fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(input_path):\n",
    "    \"\"\"\n",
    "    A function to read text from images.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(input_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons la fonction sur une image plus difficile :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714048668/image_9eadc06079.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image représente un plus grand défi, car elle contient plus de symboles de ponctuation et du texte dans des polices différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home >» Tutorials > Data Engineering\n",
      "\n",
      "Snowflake Tutorial For Beginners:\n",
      "From Architecture to Running\n",
      "Databases\n",
      "\n",
      "Learn the fundamentals of cloud data warehouse management using\n",
      "Snowflake. Snowflake is a cloud-based platform that offers significant\n",
      "benefits for companies wanting to extract as much insight from their data as\n",
      "quickly and efficiently as possible.\n",
      "\n",
      "Jan 2024 - 12 min read\n"
     ]
    }
   ],
   "source": [
    "# Define image path\n",
    "medium_text_path = \"../data/tutorial/images/medium_text.jpg\"\n",
    "\n",
    "# Extract text\n",
    "extracted_text = image_to_text(medium_text_path)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre fonction a fonctionné presque parfaitement. Il a confondu l'un des points et le signe \">\", mais le résultat est acceptable par ailleurs.\n",
    "\n",
    "\n",
    "# <span style='background:blue'>Dessiner des cadres autour du texte</span>\n",
    "\n",
    "Une opération courante de l'OCR consiste à tracer des boîtes de délimitation autour du texte. Cette opération est prise en charge par PyTesseract.\n",
    "\n",
    "Tout d'abord, nous transmettons une image chargée à la fonction image_to_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import Output\n",
    "\n",
    "# Extract recognized data from easy text\n",
    "data = pytesseract.image_to_data(easy_img, output_type=Output.DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie Output.DICT garantit que les détails de l'image sont renvoyés sous forme de dictionnaire. Jetons un coup d'œil à l'intérieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'level': [1, 2, 3, 4, 5, 2, 3, 4, 5, 5, 5, 4, 5, 5, 5],\n",
       " 'page_num': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'block_num': [0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       " 'par_num': [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'line_num': [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
       " 'word_num': [0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 3, 0, 1, 2, 3],\n",
       " 'left': [0, 0, 0, 0, 0, 60, 60, 154, 154, 394, 639, 60, 60, 298, 446],\n",
       " 'top': [0, 0, 0, 0, 0, 74, 74, 74, 74, 79, 74, 178, 190, 178, 178],\n",
       " 'width': [859,\n",
       "  859,\n",
       "  859,\n",
       "  859,\n",
       "  859,\n",
       "  748,\n",
       "  748,\n",
       "  569,\n",
       "  183,\n",
       "  185,\n",
       "  84,\n",
       "  748,\n",
       "  184,\n",
       "  88,\n",
       "  362],\n",
       " 'height': [288, 288, 288, 288, 288, 178, 178, 62, 62, 57, 62, 74, 62, 56, 56],\n",
       " 'conf': [-1, -1, -1, -1, 95, -1, -1, -1, 96, 95, 95, -1, 96, 96, 96],\n",
       " 'text': ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'This',\n",
       "  'text',\n",
       "  'is',\n",
       "  '',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'extract.']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dictionnaire contient de nombreuses informations sur l'image. Remarquez tout d'abord les touches conf et text. Ils ont tous deux une longueur de 11 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela signifie que pytesseract a tiré 15 boîtes. Le site conf est synonyme de confiance. S'il est égal à -1, le cadre correspondant est dessiné autour de blocs de texte plutôt que de mots individuels.\n",
    "\n",
    "Par exemple, si vous regardez les quatre premières valeurs width et height, elles sont grandes par rapport aux autres parce que ces boîtes sont dessinées autour du texte entier au milieu, puis pour chaque ligne de texte et pour l'image globale elle-même.\n",
    "\n",
    "En outre :\n",
    "\n",
    "    left est la distance entre le coin supérieur gauche de la boîte englobante et le bord gauche de l'image.\n",
    "    top est la distance entre le coin supérieur gauche de la boîte englobante et le bord supérieur de l'image.\n",
    "    width et height sont la largeur et la hauteur de la boîte de délimitation.\n",
    "\n",
    "À l'aide de ces informations, dessinons les boîtes sur l'image dans OpenCV.\n",
    "\n",
    "Tout d'abord, nous extrayons à nouveau les données et leur longueur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import Output\n",
    "\n",
    "# Extract recognized data\n",
    "data = pytesseract.image_to_data(easy_img, output_type=Output.DICT)\n",
    "n_boxes = len(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous créons une boucle pour le nombre de boîtes trouvées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_boxes):\n",
    "    if data[\"conf\"][i] == -1:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À l'intérieur de la boucle, nous créons une condition qui permet d'ignorer l'itération actuelle de la boucle si conf est égal à -1. Le fait de ne pas prendre en compte les boîtes de délimitation plus grandes permet de conserver une image propre.\n",
    "\n",
    "Ensuite, nous définissons les coordonnées de la boîte actuelle, en particulier les emplacements des coins supérieur gauche et inférieur droit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_boxes):\n",
    "    if data[\"conf\"][i] == -1:\n",
    "        continue\n",
    "    # Coordinates\n",
    "    x, y = data[\"left\"][i], data[\"top\"][i]\n",
    "    w, h = data[\"width\"][i], data[\"height\"][i]\n",
    "\n",
    "    # Corners\n",
    "    top_left = (x, y)\n",
    "    bottom_right = (x + w, y + h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir défini certains paramètres de la boîte, tels que sa couleur et son épaisseur en pixels, nous transmettons toutes les informations à la fonction cv2.rectangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_boxes):\n",
    "    if data[\"conf\"][i] == -1:\n",
    "        continue\n",
    "    # Coordinates\n",
    "    x, y = data[\"left\"][i], data[\"top\"][i]\n",
    "    w, h = data[\"width\"][i], data[\"height\"][i]\n",
    "\n",
    "    # Corners\n",
    "    top_left = (x, y)\n",
    "    bottom_right = (x + w, y + h)\n",
    "\n",
    "    # Box params\n",
    "    green = (0, 255, 0)\n",
    "    thickness = 3  # pixels\n",
    "\n",
    "    cv2.rectangle(\n",
    "        img=easy_img, pt1=top_left, pt2=bottom_right, color=green, thickness=thickness\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction dessine les cases sur les images originales. Sauvegardons l'image et jetons un coup d'œil :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the image\n",
    "output_image_path = \"../data/tutorial/images/text_with_boxes.jpg\"\n",
    "cv2.imwrite(output_image_path, easy_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049096/image_173eb30226.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est exactement ce que nous voulions !\n",
    "\n",
    "Maintenant, mettons à nouveau tout ce que nous avons fait dans une fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(input_img_path, output_path):\n",
    "    img = cv2.imread(input_img_path)\n",
    "\n",
    "    # Extract data\n",
    "    data = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "    n_boxes = len(data[\"text\"])\n",
    "\n",
    "    for i in range(n_boxes):\n",
    "        if data[\"conf\"][i] == -1:\n",
    "            continue\n",
    "        # Coordinates\n",
    "        x, y = data[\"left\"][i], data[\"top\"][i]\n",
    "        w, h = data[\"width\"][i], data[\"height\"][i]\n",
    "\n",
    "        # Corners\n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x + w, y + h)\n",
    "\n",
    "        # Box params\n",
    "        green = (0, 255, 0)\n",
    "        thickness = 1  # The function-version uses thinner lines\n",
    "\n",
    "        cv2.rectangle(img, top_left, bottom_right, green, thickness)\n",
    "\n",
    "    # Save the image with boxes\n",
    "    cv2.imwrite(output_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et utilisez la fonction sur le texte moyennement dur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/tutorial/images/medium_text_with_boxes.png\"\n",
    "\n",
    "draw_bounding_boxes(medium_text_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049157/image_41aa62ce70.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même pour l'image la plus difficile, le résultat est parfait !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Étude de cas : OCR sur un fichier PDF avec Python</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons une étude de cas sur un exemple de fichier PDF numérisé. Dans la pratique, il est très probable que vous travailliez avec des PDF numérisés plutôt qu'avec des images, comme celle-ci :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049144/image_b7d645a670.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez télécharger le PDF depuis cette page de mon GitHub.\n",
    "\n",
    "L'étape suivante consiste à installer la bibliothèque pdf2image, qui nécessite un logiciel de traitement des PDF appelé Poppler. Voici les instructions spécifiques à chaque plate-forme :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour Windows, vous pouvez suivre les instructions de la documentation de PDF2Image.\n",
    "\n",
    "Après l'installation, nous importons les modules appropriés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction convert_from_path convertit un PDF donné en une série d'images. Voici une fonction qui enregistre chaque page d'un fichier PDF sous forme d'image dans un répertoire donné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_image(pdf_path, output_folder: str = \".\"):\n",
    "    \"\"\"\n",
    "    A function to convert PDF files to images\n",
    "    \"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not Path(output_folder).exists():\n",
    "        Path(output_folder).mkdir()\n",
    "\n",
    "    pages = convert_from_path(pdf_path, output_folder=output_folder, fmt=\"png\")\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécutons-le sur notre document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pierr\\VSC_Projects\\Rpur\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Afficher le répertoire courant\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1662x2341>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"scanned_document.pdf\"\n",
    "\n",
    "pdf_to_image(pdf_path, output_folder=\"documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est une liste contenant un seul objet image PngImageFile. Jetons un coup d'œil au répertoire documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS\n",
      " Le num�ro de s�rie du volume est 7069-5260\n",
      "\n",
      " R�pertoire de c:\\Users\\pierr\\VSC_Projects\\Rpur\\documents\n",
      "\n",
      "10/03/2025  22:13    <DIR>          .\n",
      "10/03/2025  22:09    <DIR>          ..\n",
      "10/03/2025  22:13         2�027�262 49e107d4-9cea-4b47-880f-e1ae44ce12cb-1.png\n",
      "               1 fichier(s)        2�027�262 octets\n",
      "               2 R�p(s)  79�204�216�832 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image est là, alors envoyons-la à la fonction image_to_text que nous avons créée au début et imprimons les quelques centaines de caractères du texte extrait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFU Business report\n",
      "\n",
      "New customer's development\n",
      "and increasing the sale of product\n",
      "\n",
      "My country economy at this season keeps escaping from Odoba of business though holds a crude oil\n",
      "high so on unstable element that continues still, and recovering gradually and well.\n",
      "In the IT industry, there is an influence such as competing intensification in narrowing investment field.\n",
      "\n",
      "[Th\n"
     ]
    }
   ],
   "source": [
    "scanned_img_path = \"../data/tutorial/documents/49e107d4-9cea-4b47-880f-e1ae44ce12cb-1.png\"\n",
    "\n",
    "print(image_to_text(scanned_img_path)[:377])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous comparons le texte au fichier, tout fonctionne bien - le formatage et l'espacement sont préservés et le texte est exact. Comment partager le texte extrait ?\n",
    "\n",
    "Le meilleur format pour partager un texte PDF extrait est un autre fichier PDF ! PyTesseract dispose d'une fonction image_to_pdf_or_hocr qui prend n'importe quelle image avec du texte et la convertit en un fichier PDF brut, consultable par le texte. Utilisons-le sur notre image numérisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "raw_pdf = pytesseract.image_to_pdf_or_hocr(scanned_img_path)\n",
    "\n",
    "with open(\"searchable_pdf.pdf\", \"w+b\") as f:\n",
    "    f.write(bytearray(raw_pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voici à quoi ressemble le site searchable_pdf:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049439/image_bf9f396abc.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le constater, je peux surligner et copier du texte à partir du fichier. En outre, tous les éléments du PDF original sont préservés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Techniques de prétraitement d'images pour l'OCR dans OpenCV</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'existe pas d'approche unique pour l'OCR. Les techniques que nous avons abordées aujourd'hui peuvent ne pas fonctionner avec d'autres types d'images. Je vous recommande d'expérimenter différentes techniques de prétraitement d'images et configurations de Tesseract afin de trouver les paramètres optimaux pour des images spécifiques.\n",
    "\n",
    "Le facteur le plus important de l'OCR est la qualité de l'image. Les images correctement numérisées, entièrement verticales et très contrastées (en noir et blanc) sont celles qui fonctionnent le mieux avec les logiciels d'OCR. N'oubliez pas que ce n'est pas parce que vous pouvez lire le texte que votre ordinateur le peut.\n",
    "\n",
    "Si vos images ne satisfont pas aux normes de qualité élevées de Tesseract et que le résultat est un charabia, vous pouvez effectuer quelques étapes de prétraitement.\n",
    "\n",
    "## <span style='background:green'>1.  Conversion en niveaux de gris</span>\n",
    "\n",
    "\n",
    "Commencez par convertir les images colorées en niveaux de gris. Cela permet d'améliorer la précision en supprimant les variations de couleur susceptibles de perturber le processus de reconnaissance. Dans OpenCV, cela ressemble à ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    \"\"\"Converts an image to grayscale.\n",
    "\n",
    "    Args:\n",
    "        image: The input image in BGR format.\n",
    "\n",
    "    Returns:\n",
    "        The grayscale image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:green'>2.  Réduction du bruit</span>\n",
    "\n",
    "Toutes les images, en particulier les documents numérisés, ne sont pas accompagnées d'un arrière-plan immaculé et uniforme. En outre, certaines images peuvent provenir de documents anciens dont les pages se sont détériorées en raison de l'âge. En voici un exemple :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049489/image_b38ea70997.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez des techniques telles que des filtres de débruitage (par exemple, le flou médian) pour réduire les artefacts de bruit dans l'image qui peuvent conduire à des erreurs d'interprétation lors de l'OCR. Dans OpenCV, vous pouvez utiliser la fonction medianBlur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def denoise(image):\n",
    "    \"\"\"Reduces noise in the image using a median blur filter.\n",
    "\n",
    "    Args:\n",
    "        image: The input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        The denoised image.\n",
    "    \"\"\"\n",
    "    return cv2.medianBlur(image, 5)  # Adjust kernel size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:green'>3.  Affûtage</span>\n",
    "\n",
    "Dans certains cas, l'accentuation de la netteté de l'image peut renforcer les contours et améliorer la reconnaissance des caractères, en particulier pour les images floues ou à faible résolution. L'accentuation peut être réalisée en appliquant un filtre Laplacien dans OpenCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def sharpen(image):\n",
    "    \"\"\"Sharpens the image using a Laplacian filter.\n",
    "\n",
    "    Args:\n",
    "        image: The input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        The sharpened image (be cautious with sharpening).\n",
    "    \"\"\"\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(image, -1, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:green'>4.  Binarisation</span>\n",
    "\n",
    "Pour certaines images, la binarisation (conversion de l'image en noir et blanc) peut être bénéfique. Expérimentez différentes techniques de seuillage pour trouver la séparation optimale entre le premier plan (texte) et l'arrière-plan.\n",
    "\n",
    "Cependant, la binarisation peut être sensible aux variations d'éclairage et n'est pas toujours nécessaire. Voici un exemple d'image binarisée :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://media.datacamp.com/legacy/v1714049545/image_99bfaa0e01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer une binarisation dans OpenCV, vous pouvez utiliser la fonction adaptiveThreshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def binarize(image):\n",
    "    \"\"\"Binarizes the image using adaptive thresholding.\n",
    "\n",
    "    Args:\n",
    "        image: The input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        The binary image.\n",
    "    \"\"\"\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:green'>5.  Autres techniques</span>\n",
    "\n",
    "Il existe de nombreuses autres techniques de prétraitement, telles que :\n",
    "\n",
    "    Dilatation : rendre les polices petites et fines plus grasses pour améliorer la reconnaissance.\n",
    "    Érosion : érosion du texte en gras pour améliorer la précision. Fréquent dans les documents historiques avec des polices de caractères épaisses.\n",
    "    Détection d'arêtes Canny\n",
    "    Correction de l'obliquité : correction de l'inclinaison (obliquité) des lignes de texte. Fréquent dans les documents mal numérisés\n",
    "\n",
    "Vous pouvez en savoir plus sur les améliorations de la qualité de l'image en consultant cette page de la documentation de Tesseract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Conclusion</span>\n",
    "\n",
    "Dans cet article, vous avez fait les premiers pas pour vous familiariser avec le problème dynamique qu'est l'OCR. Nous avons d'abord abordé la question de l'extraction de texte à partir d'images simples, puis nous sommes passés à des images plus difficiles avec un formatage complexe.\n",
    "\n",
    "Nous avons également appris un processus de bout en bout pour extraire du texte à partir de PDF numérisés et comment enregistrer le texte extrait au format PDF pour qu'il puisse faire l'objet d'une recherche. Nous avons terminé l'article avec quelques conseils pour améliorer la qualité des images avec OpenCV avant de les envoyer à Tesseract.\n",
    "\n",
    "Si vous souhaitez en savoir plus sur la résolution de problèmes liés à l'image, voici quelques ressources sur la vision par ordinateur :\n",
    "\n",
    "    Cours sur le traitement d'images en Python\n",
    "    Tutoriel sur les CNN en Python\n",
    "    Traitement d'images avec le cursus Python - une collection de cours\n",
    "    Tutoriel OpenCV en Python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
